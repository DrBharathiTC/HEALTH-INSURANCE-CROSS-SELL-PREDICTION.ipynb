{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrBharathiTC/HEALTH-INSURANCE-CROSS-SELL-PREDICTION.ipynb/blob/main/HEALTH_INSURANCE_CROSS_SELL_PREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGcl5Bv9ed6u"
      },
      "source": [
        "# **Problem Statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJAmGx75jJk1"
      },
      "source": [
        "Our client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n",
        "\n",
        "An insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee.\n",
        "\n",
        "For example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n",
        "\n",
        "Just like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called ‘sum assured’) to the customer.\n",
        "\n",
        "Building a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimise its business model and revenue.\n",
        "\n",
        "Now, in order to predict, whether the customer would be interested in Vehicle insurance, you have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzGDqdC4fZ-b"
      },
      "source": [
        "# **Attribute Information**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEJxl68MjYbs"
      },
      "source": [
        "1. id :\tUnique ID for the customer\n",
        "\n",
        "2. Gender\t: Gender of the customer\n",
        "\n",
        "3. Age :\tAge of the customer\n",
        "\n",
        "4. Driving_License\t0 : Customer does not have DL, 1 : Customer already has DL\n",
        "\n",
        "5. Region_Code :\tUnique code for the region of the customer\n",
        "\n",
        "6. Previously_Insured\t: 1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance\n",
        "\n",
        "7. Vehicle_Age :\tAge of the Vehicle\n",
        "\n",
        "8. Vehicle_Damage\t :1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past.\n",
        "\n",
        "9. Annual_Premium\t: The amount customer needs to pay as premium in the year\n",
        "\n",
        "10. PolicySalesChannel :\tAnonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.\n",
        "\n",
        "11. Vintage :\tNumber of Days, Customer has been associated with the company\n",
        "\n",
        "12. Response :\t1 : Customer is interested, 0 : Customer is not interested"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Contents**\n",
        "\n",
        "\n",
        "*Importing Libraries\n",
        "*Import Data\n",
        "*Data Summary\n",
        "*Data Visualization\n",
        "*Data Cleaning ( EDA )\n",
        "*Feature Selection\n",
        "*Model Selection\n",
        "*Hyperparameter Tuning\n",
        "*Conclusion"
      ],
      "metadata": {
        "id": "Bciu4KWV5aMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing package\n",
        "!pip install pandas-profiling==2.7.1"
      ],
      "metadata": {
        "id": "GP-ewuH2ZrgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-optimize "
      ],
      "metadata": {
        "id": "bPcNIoyWZz-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Importing Libraries"
      ],
      "metadata": {
        "id": "p34YxeHDAFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import lightgbm as ltb\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from skopt import BayesSearchCV\n",
        "import time\n",
        "from math import sqrt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
        "from skopt.space import Real, Categorical, Integer"
      ],
      "metadata": {
        "id": "JhrNde7oZ7d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import Data"
      ],
      "metadata": {
        "id": "k36XTERvAeNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "4rzC5oiVAg26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DF1=pd.read_csv(\"/content/drive/My Drive/almabetter projects/Health insurance cross cell prediction/TRAIN-HEALTH INSURANCE CROSS SELL PREDICTION.csv\")"
      ],
      "metadata": {
        "id": "ZaqTU6G9Ra6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Copying the dataset\n",
        "HIDF1=DF1.copy()"
      ],
      "metadata": {
        "id": "hQ34clLVaYgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data Summary"
      ],
      "metadata": {
        "id": "V5ZFvMV1T53X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.head()"
      ],
      "metadata": {
        "id": "tip4IxOvT3bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.tail()"
      ],
      "metadata": {
        "id": "1aio1xpOUVcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.info()"
      ],
      "metadata": {
        "id": "Nj3uKdrOUl1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.shape"
      ],
      "metadata": {
        "id": "bctbocPUUoxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.columns"
      ],
      "metadata": {
        "id": "L03_bTXtU5xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset details**\n",
        "A new DataFrame where we have columns name of this df along with datatype , missing value no , unique values no , first value , second value"
      ],
      "metadata": {
        "id": "nDY_JorBiqta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DataInfoAll(HIDF1):\n",
        "    print(f\"Dataset Shape: {HIDF1.shape}\")\n",
        "    print(\"-\"*75)\n",
        "    summary = pd.DataFrame(HIDF1.dtypes,columns=['dtypes'])\n",
        "    summary = summary.reset_index()\n",
        "    summary['Name'] = summary['index']\n",
        "    summary = summary[['Name','dtypes']]\n",
        "    summary['Missing'] = HIDF1.isnull().sum().values    \n",
        "    summary['Uniques'] = HIDF1.nunique().values\n",
        "    summary['First Value'] = HIDF1.iloc[0].values\n",
        "    summary['Second Value'] = HIDF1.iloc[1].values\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "j9D6nw-UiitC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataInfoAll(HIDF1)"
      ],
      "metadata": {
        "id": "9LDfk6Ml1YiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no Null value present in this dataset.\n",
        "All the numerical values are present in integer or float datatype "
      ],
      "metadata": {
        "id": "gJclVhWl2GIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Let's check outlier present in all numerical columns* "
      ],
      "metadata": {
        "id": "wQ38Zw-r8kFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize']=(20,10)\n",
        "ax =HIDF1[list(HIDF1.describe())].plot(kind='box', title='Boxplot', showmeans=True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1BtAhO5A8ciS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see\n",
        "* Annual_Premium has the highest outliers present in this dataset\n",
        "* Driving_License has very less outliers.\n",
        "* Response has very less outliers."
      ],
      "metadata": {
        "id": "HYCld55Z8_4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.describe()"
      ],
      "metadata": {
        "id": "FMD51vzfe4kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking duplicate values"
      ],
      "metadata": {
        "id": "Oy6Q9w-47EQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate = HIDF1[HIDF1.duplicated()]\n",
        "print(f\"There are {duplicate.shape[0]} duplicate rows present in the dataset.\")"
      ],
      "metadata": {
        "id": "WZdbzczE68ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking NaN values"
      ],
      "metadata": {
        "id": "PwX87Qaw7c8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.isna().sum().to_frame().T"
      ],
      "metadata": {
        "id": "CNTQFSHj7cHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical features statistics details\n",
        "\n",
        "The following argument will help us to mention categorical columns and will also show a summary of all the categorical features.\n",
        "\n"
      ],
      "metadata": {
        "id": "0dgeFyF6dMcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.describe(include='O')"
      ],
      "metadata": {
        "id": "rk9-R1L5dUQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation -\n",
        "\n",
        "In our dataset, there are more men than women.\n",
        "The age range of 1-2 year vehicles is higher in our dataset.\n",
        "Many of the clients' vehicles have been damaged."
      ],
      "metadata": {
        "id": "SEiOzG-6dkj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Visualization**  - Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "jhMqyMZz7zXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Target Variable"
      ],
      "metadata": {
        "id": "Gf3sxssy744a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing target column into a variable \n",
        "Dependent_variable = HIDF1['Response']"
      ],
      "metadata": {
        "id": "KSZhDo94eG7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"darkgrid\")\n",
        "sns.countplot(x='Response', data=HIDF1)\n",
        "plt.title('Not-Interested vs Interested Policyholders', fontsize=20) #title for the countplot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h_nnPiWx5vrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The data is highly imbalanced.\n",
        "As you can see in above graph, there are very few interested customers whose stats are less than 50000 and those above 300000 are not interested"
      ],
      "metadata": {
        "id": "chF-P61d8PKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.Response.value_counts()/HIDF1.shape[0]"
      ],
      "metadata": {
        "id": "oitC350be6cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation -\n",
        "\n",
        "The dependant variable has binary values of 0 and 1. We can infer from the plot above that many clients have no interest in purchasing vehicle insurance. 12.2 percent of the data are 1's and 87.7 percent of the data are 0s. This data must be handled using the imbalance technique since the output feature is unbalanced."
      ],
      "metadata": {
        "id": "IynNgZntfBqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gender"
      ],
      "metadata": {
        "id": "hONJilUb9fAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (13,5))\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='Gender', data=HIDF1, palette='husl')\n",
        "plt.title(\"Count of Male & Female\")\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x='Gender', hue='Response', data=HIDF1, palette=\"husl\")\n",
        "plt.title(\"Response in Male and Female Category\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qgFGb7Jt6TpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = HIDF1.groupby('Gender')['Age'].mean()\n",
        "a"
      ],
      "metadata": {
        "id": "xny1tJGIgqXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The gender variable ratio in the dataset is almost equal, male category is slightly more than female and also the chances of buying insurance is also little high than female.\n",
        "\n",
        "* The number of male is greater than 200000 and The number of female is close to 175000. The number of male is intersted which is greater than 25000 and The number of female is intersted which is below 25000.Male category is slightly greater than that of female and chances of buying the insurance is also little high"
      ],
      "metadata": {
        "id": "UqhvIS95-BPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Age vs Response"
      ],
      "metadata": {
        "id": "-Sh7rJBS-Ife"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Age VS Response\n",
        "plt.figure(figsize=(20,10))\n",
        "sns.countplot(x='Age',hue='Response',data=HIDF1)"
      ],
      "metadata": {
        "id": "2fvBdE5pAPrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Young people below 30 are not interested in vehicle insurance. Reasons could be lack of experience, less maturity level and they don't have expensive vehicles yet.\n",
        "* People aged between 30-60 are more likely to be interested.\n",
        "\n"
      ],
      "metadata": {
        "id": "m9qHbOCsAnUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(HIDF1['Age'])"
      ],
      "metadata": {
        "id": "Gpr8oIXSAdTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see there is no outliers present in Age"
      ],
      "metadata": {
        "id": "L-ZkAe0SA6qT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.Driving_License.value_counts()"
      ],
      "metadata": {
        "id": "bnkhSEweA-wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8, 5))\n",
        "sns.countplot(x='Driving_License', hue='Response', data=HIDF1)"
      ],
      "metadata": {
        "id": "Gg6Kpyae7ycp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Customers who are interested in Vehicle Insurance almost all have driving license\n"
      ],
      "metadata": {
        "id": "cJvr0JQIBmQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Previously_Insured Vs Response"
      ],
      "metadata": {
        "id": "v6WVOX7dBro1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure( figsize = (10 , 6))\n",
        "sns.countplot(x = 'Previously_Insured' , hue = 'Response' , data = HIDF1 , palette = 'husl' )"
      ],
      "metadata": {
        "id": "AouXm8hZB_bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Those who have not insurance some of them are taking insurance"
      ],
      "metadata": {
        "id": "zYtX9_7SCGdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vehicle_Age Vs Response"
      ],
      "metadata": {
        "id": "4HUpzi3qCL3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIDF1.Vehicle_Age.value_counts()"
      ],
      "metadata": {
        "id": "atF6gedtCQGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure( figsize = (10 , 6))\n",
        "sns.countplot(x = 'Vehicle_Age' , hue = 'Response' , data = HIDF1 , palette = 'husl')\n",
        "plt.axis([None,None,10,175000])"
      ],
      "metadata": {
        "id": "4Ki6fYNgCcjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From seeing this graph we can say that if the vehicle's age is in between 1 to 2 years ,those vehicle owners are more likely to buy insurance\n",
        "\n",
        "* No of customers with Vehicle_Age >2 is more than the no of customers whose Vehicle_Age< 1"
      ],
      "metadata": {
        "id": "knT__wErCkeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Region code Vs Response"
      ],
      "metadata": {
        "id": "RYH-99t5hxBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,15))\n",
        "sns.countplot(x='Region_Code', hue='Response', data=HIDF1)\n",
        "plt.title('Response in terms of Region_Code', fontsize=15)"
      ],
      "metadata": {
        "id": "wa-Xnwrgh1IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Region Code - 0.28 has more customers\n"
      ],
      "metadata": {
        "id": "OGa4aIcpiOC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vehicle_Damage Vs Response"
      ],
      "metadata": {
        "id": "a8tN0Rh9icZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=HIDF1['Vehicle_Damage'], data=HIDF1)\n",
        "plt.title('Vehicle Damage Status', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XiUurxiciZrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can infer from the above plot that the number of policyholders for both vehicle damage statuses are almost equal."
      ],
      "metadata": {
        "id": "Q6dtjN9Si4k2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Annual_Premium"
      ],
      "metadata": {
        "id": "HJwb4G-9CqVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,7))\n",
        "plt.subplot(2,1,1)\n",
        "sns.distplot(HIDF1['Annual_Premium'], color='green')\n",
        "plt.title(\"Distribution of Annual premium\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5WVO7ZDHCyDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From the distribution plot we can infer that the annual premimum variable is right skewed.\n"
      ],
      "metadata": {
        "id": "03y-yXVxC7Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,7))\n",
        "sns.boxplot(HIDF1['Annual_Premium'])\n",
        "plt.title(\"boxplot of Annual premium\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ow41I2weDB45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As you can see that in the column Annual_premium there are many outliers present"
      ],
      "metadata": {
        "id": "uX4kEUIeDJS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coverting Categorical columns into Numerical columns using Encoding techniques\n"
      ],
      "metadata": {
        "id": "5mqOWkpvYWRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Encoding on Vehicle_Age and Vehicle_Damage columns"
      ],
      "metadata": {
        "id": "itjl8uiYYf0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn. preprocessing import LabelEncoder\n",
        "#changing categorical value to numerical values\n",
        "labelEncoder= LabelEncoder()\n",
        "HIDF1['Vehicle_Age'] = labelEncoder.fit_transform(HIDF1['Vehicle_Age'])\n",
        "HIDF1['Vehicle_Damage'] = labelEncoder.fit_transform(HIDF1['Vehicle_Damage'])"
      ],
      "metadata": {
        "id": "u24Hs3L9YfQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One Hot Encoding on Gender Column"
      ],
      "metadata": {
        "id": "dK_dC0OzYv4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encoder on Gender\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc=OneHotEncoder()\n",
        "enc_data=pd.DataFrame(enc.fit_transform(HIDF1[['Gender']]).toarray())\n",
        "names=enc.get_feature_names_out()\n",
        "enc_data.columns=names\n",
        "df1=HIDF1.join(enc_data)"
      ],
      "metadata": {
        "id": "K0wXYIUmYzaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data after Encoding\n",
        "df1.info()"
      ],
      "metadata": {
        "id": "mfKRbFVwY_eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation -\n",
        "\n",
        "We can see that all columns have been numerically converted.\n",
        "\n",
        "We are removing the gender column since we have separated into two columns, Gender Female and Gender Male."
      ],
      "metadata": {
        "id": "Z8agv4vGnBZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Gender feature\n",
        "df1.drop('Gender',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "g87IGnx1nIXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking shape after adding/removing features\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "KVnaJBKvnL5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "Q4QSmYbcnRix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Once again checking the duplicates\n",
        "duplicate = df1[df1.duplicated()]\n",
        "print(duplicate)"
      ],
      "metadata": {
        "id": "n91z0SS0nWQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Duplicates found in this dataset."
      ],
      "metadata": {
        "id": "hWtDj-YZnhFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variance Threshold Removal\n",
        "\n",
        "Using this method we can check which columns have constant values."
      ],
      "metadata": {
        "id": "6Dpd55u82E17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold"
      ],
      "metadata": {
        "id": "KXwTY11b2KGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementation Variance Threshold\n",
        "variance_threshold = VarianceThreshold(threshold=0)\n",
        "variance_threshold.fit(df1)\n",
        "variance_threshold.get_support()"
      ],
      "metadata": {
        "id": "WvcTpvaF2PhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation -\n",
        "\n",
        "In our data set, there isn't a single column with constant values.italicised text"
      ],
      "metadata": {
        "id": "XwmVeh6g2v7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection using f_classification\n",
        "## Seperating Dependent and Independent Variables"
      ],
      "metadata": {
        "id": "M7GZ9irk3KYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the libraries\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif"
      ],
      "metadata": {
        "id": "VQYuuzCD3Tmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "independent = df1.drop(['Response'], axis=1) #Contain all independent variables\n",
        "dependent = df1['Response'] #Contain Dependent variable"
      ],
      "metadata": {
        "id": "5QFkybFS3WWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding scores of each feature\n",
        "f_scores = f_classif(independent, dependent)\n",
        "f_scores"
      ],
      "metadata": {
        "id": "KgYH_YvO3Y__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The Second array consists of p-values that we need.\n",
        "p_values = pd.Series(f_scores[1], index= independent.columns)\n",
        "p_values.plot(kind='bar', color='blue', figsize=(16,5))\n",
        "plt.title('p-value scores for numerical features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yYKX2izD3bvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can drop Id and Vintage columns as per the above chart."
      ],
      "metadata": {
        "id": "wFd7d1r33fmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance"
      ],
      "metadata": {
        "id": "P48IoCqh3gXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Feature importance by using RandomForestClassifier\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Create the random forest with hyperparameters\n",
        "model= RandomForestClassifier(n_estimators=340)\n",
        "# Fit the mmodel\n",
        "model.fit(independent,dependent)\n",
        "# get the importance of thr resulting features\n",
        "importances= model.feature_importances_\n",
        "# Create a data frame for visualization\n",
        "final_df= pd.DataFrame({\"Features\": pd.DataFrame(independent).columns, \"Importances\": importances})\n",
        "final_df.set_index('Importances')\n",
        "# Sort in ascending order to better visualization\n",
        "final_df= final_df.sort_values('Importances')\n",
        "# Plot the feature importances in bars\n",
        "final_df.plot.bar(color='teal')"
      ],
      "metadata": {
        "id": "lBVszYNk4c9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   So after doing F_Classifier and RandomForestClassifier we can observe that id,vintage,Gender are less important. So we can drop those columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "SohNUCu34giD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "B9Y7xfj-5-fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(['id','Vintage'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "z9Y47EP1469r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation Feature Selection\n"
      ],
      "metadata": {
        "id": "ayEAKUt4DNOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking correlation of all the columns using heatmap\n",
        "plt.figure(figsize = (18,10))\n",
        "correlation = df1.corr()\n",
        "sns.heatmap(correlation, annot= True,linewidths=3,cmap='coolwarm')\n",
        "plt.title(\"Pearson correlation of Features\", y=1.05, size=15)"
      ],
      "metadata": {
        "id": "rNPSZEQG5H_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations based on correlation plot:-\n",
        "\n",
        "Gender_female and male 100% Multicollinearity we can remove any one feature among these 2\n",
        "Previously insured and vechicle_damage have high correlations with dependent variable"
      ],
      "metadata": {
        "id": "2xIrpkeN5PmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping gender female\n",
        "df1.drop('Gender_Female',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "aAeE1rJj5cyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obsservation-\n",
        "\n",
        "We have remove Gender_female since it has 100% Multicollinearity with male columns. So, we can remove any one feature among these 2."
      ],
      "metadata": {
        "id": "BXC7vw-NClyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking shape after removing 3 columns\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "61ytuXpNCzla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final dataset shape will be used in Model Training."
      ],
      "metadata": {
        "id": "xxgZs8ZoC3Fg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train & Test data"
      ],
      "metadata": {
        "id": "gfr3xFntMOd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test data\n",
        "\n",
        "X = df1.drop(['Response'], axis=1) #Contain all independent variables\n",
        "y = df1['Response'] "
      ],
      "metadata": {
        "id": "E3j2-Gm1MOJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=.30,random_state=0)\n",
        "print(Xtrain.shape,Xtest.shape,ytrain.shape,ytest.shape)"
      ],
      "metadata": {
        "id": "Lagpb1reMguM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make a list to get most important Features\n",
        "train_col_list = list(Xtrain.columns)\n",
        "train_col_list"
      ],
      "metadata": {
        "id": "n81Vo4ClMmNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = ytrain.values.reshape(-1,1)"
      ],
      "metadata": {
        "id": "lR3i2pTAMq34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytest = ytest.values.reshape(-1,1)"
      ],
      "metadata": {
        "id": "HXect82zMu4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain.shape"
      ],
      "metadata": {
        "id": "bhXhVmlpMxs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytest.shape"
      ],
      "metadata": {
        "id": "sovSn1WAM1bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Handling Imbalanced data**\n",
        "\n",
        "One of the most significant challenges when dealing with unbalanced datasets is the metrics used to evaluate their model. Using simpler metrics, such as accuracy score, can be misleading. In a dataset with highly unbalanced classes, the classifier will always \"predict\" the most common class without performing any feature analysis, and while it will have a high accuracy rate, it will often be incorrect."
      ],
      "metadata": {
        "id": "aTpgdqd-M6fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Over Sampling Technique"
      ],
      "metadata": {
        "id": "pxr8z2wGNHgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state = 42)\n",
        "X_ros, y_ros = ros.fit_resample(Xtrain, ytrain)\n",
        "\n",
        "print('Original dataset shape', len(HIDF1))\n",
        "print('Resampled dataset shape', len(y_ros))\n",
        "print('Resampled dataset shape', len(X_ros))\n",
        "print('Resampled dataset shape', len(ytrain))\n",
        "print('Resampled dataset shape', len(Xtrain))"
      ],
      "metadata": {
        "id": "_D_idzCqNL42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation-\n",
        "\n",
        "The dataset has now been balanced using the oversampling technique, and it is ready for training the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "M-fue-laN0OP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Scaling"
      ],
      "metadata": {
        "id": "ln_yNBWgN7j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_ros = scaler.fit_transform(X_ros)\n",
        "Xtest = scaler.transform(Xtest)"
      ],
      "metadata": {
        "id": "n0C2nzJoN-ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        "\n",
        "*   Scaled down the train varible which makes easy for a model to learn.\n",
        "\n"
      ],
      "metadata": {
        "id": "tCKEZEV9ORax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "ab-oPmvJOez8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "3xv2a8bQPoa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining all these models\n",
        "models = [\n",
        "           ['LinearClassifier: ', Perceptron()],\n",
        "           ['LogisticRegresseer:', LogisticRegression()],\n",
        "           ['GNB: ', GaussianNB()],\n",
        "           ['BNB: ', BernoulliNB()],\n",
        "           ['KNeighborsClassifier: ', KNeighborsClassifier()],\n",
        "           ['DecisionTreeClassifier: ', DecisionTreeClassifier()],\n",
        "           ['RandomForestClassifier ',RandomForestClassifier()],\n",
        "           ['GradientBoostingClassifier: ', GradientBoostingClassifier()] ,\n",
        "           ['XGBRFClassifier: ', XGBRFClassifier()],\n",
        "           ['AdaBoostClassifier: ',AdaBoostClassifier()],\n",
        "           ['LgbmClassifier: ', lgb.LGBMClassifier()]\n",
        "         ]"
      ],
      "metadata": {
        "id": "uti5HO_fOlSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#store all the metrics values in data frame\n",
        "import time\n",
        "model_data = []\n",
        "for name,curr_model in models :\n",
        "      curr_model_data = {}\n",
        "      curr_model.random_state = 42\n",
        "      curr_model_data[\"Name\"] = name\n",
        "      start = time.time()\n",
        "      curr_model.fit(X_ros,y_ros)\n",
        "      end = time.time()\n",
        "      y_train_pred=curr_model.predict(X_ros)\n",
        "      y_test_pred= curr_model.predict(Xtest)\n",
        "      curr_model_data[\"Train_Time\"] = end - start\n",
        "      curr_model_data[\"Train accuracy\"] =accuracy_score(y_ros,y_train_pred )\n",
        "      curr_model_data[\"Test accuracy\"] =accuracy_score(ytest, y_test_pred)\n",
        "      curr_model_data[\"Train precision\"] = precision_score(y_ros,y_train_pred)\n",
        "      curr_model_data[\"Test precision\"] = precision_score(ytest,y_test_pred)\n",
        "      curr_model_data[\"Train recall\"] = recall_score(y_ros,y_train_pred)\n",
        "      curr_model_data[\"Test recall\"] = recall_score(ytest,y_test_pred)\n",
        "      curr_model_data[\"Train f1 score\"] = f1_score(y_ros,y_train_pred)\n",
        "      curr_model_data[\"Test f1 score\"] = f1_score(ytest,y_test_pred)\n",
        "      curr_model_data['Train ROC-AUC'] = roc_auc_score(y_ros,y_train_pred)\n",
        "      curr_model_data[\"Test ROC-AUC\"] = roc_auc_score(ytest,y_test_pred)\n",
        "      model_data.append(curr_model_data)\n",
        " "
      ],
      "metadata": {
        "id": "e_s41TvSSBF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(model_data)\n",
        "results"
      ],
      "metadata": {
        "id": "pKXUyYIcF4z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation -\n",
        "\n",
        "Hurrah! Here are the results of all the models. The best evaluation metric is recall, and we can see that Boosting Algorithms are performing well in this case.\n",
        "\n",
        "However, we can perform hyperparameter tuning on these models to determine the optimum model."
      ],
      "metadata": {
        "id": "NmpAvxN6F_JF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw plot for above models metrices\n",
        "results.plot(x=\"Name\", y=['Train accuracy' , 'Test accuracy' ,'Train precision','Test precision','Train recall','Test recall','Train f1 score','Test f1 score'], kind=\"bar\" , title = 'Accuracy Score Results' , figsize= (10,8)) "
      ],
      "metadata": {
        "id": "P043dhYLGE8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation -\n",
        "\n",
        "RandomForestClassifier is performing well in terms of accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "jtRjos6BHFfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_data2 = []\n",
        "for name,curr_model in models :\n",
        "    curr_model_data = {}\n",
        "    curr_model.random_state = 42\n",
        "    curr_model_data[\"Name\"] = name\n",
        "    start = time.time()\n",
        "    curr_model.fit(X_ros,y_ros)\n",
        "    end = time.time()\n",
        "    curr_model_data[\"Train_Time\"] = end - start\n",
        "    curr_model_data[\"conf_mat\"] = confusion_matrix(ytest,[round(value) for value in (curr_model.predict(Xtest))])\n",
        "    model_data2.append(curr_model_data)"
      ],
      "metadata": {
        "id": "lScRmeOwHLSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Conf_Mat_df= pd.DataFrame(model_data2)\n",
        "Conf_Mat_df"
      ],
      "metadata": {
        "id": "wVRBeT2FHRGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation -\n",
        "\n",
        "We can observe from the confusion matrix that LgbmClassifier, XGBRFClassifier are the top models.\n"
      ],
      "metadata": {
        "id": "QEpCuN7YHWRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's perform Cross Validation and Hyper parameter tuning on these models to get better results."
      ],
      "metadata": {
        "id": "jD4X2I9gKjbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning on RandomForestClassifier"
      ],
      "metadata": {
        "id": "FzWb-OAgKonl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=40)\n",
        "#Cross validation and hyperparameter tuning\n",
        "rf_bayes = BayesSearchCV(estimator= rf,\n",
        "                         search_spaces = {\n",
        "                          'max_depth': Integer(2,100),\n",
        "                          'min_samples_leaf': Integer(1,100),\n",
        "                          'min_samples_split': Integer(2,100),\n",
        "                          'n_estimators': Integer(1,140),\n",
        "                          'max_features': [\"auto\", \"sqrt\", \"log2\"]\n",
        "                        },\n",
        "                       cv = 5, verbose=2, scoring='accuracy',n_iter=10)\n",
        "\n",
        "rf_bayes.fit(X_ros,y_ros)"
      ],
      "metadata": {
        "id": "TKMTgMUPKtOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_bayes.best_params_"
      ],
      "metadata": {
        "id": "uPPt95ofKzXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_bayes.best_estimator_"
      ],
      "metadata": {
        "id": "AbIJlSuiLEB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make prediction\n",
        "train_pred=rf_bayes.best_estimator_.predict(X_ros)\n",
        "test_pred=rf_bayes.best_estimator_.predict(Xtest)"
      ],
      "metadata": {
        "id": "MUQnIW_nLJVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating accuracy on train and test\n",
        "train_accuracy = accuracy_score(y_ros, train_pred)\n",
        "test_accuracy = accuracy_score(ytest, test_pred)\n",
        "\n",
        "print(\"The accuracy on train dataset is\", train_accuracy)\n",
        "print(\"The accuracy on test dataset is\", test_accuracy)"
      ],
      "metadata": {
        "id": "qk6S9S2nLMj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the confusion matrices for train and test\n",
        "train_cm = confusion_matrix(y_ros, train_pred)\n",
        "test_cm = confusion_matrix(ytest, test_pred)"
      ],
      "metadata": {
        "id": "PcoP-ydBLPfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cm\n",
        "test_cm"
      ],
      "metadata": {
        "id": "lrJ9OcupLSUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_ros,train_pred))\n",
        "print(\"\\n\")\n",
        "print(classification_report(ytest,test_pred))"
      ],
      "metadata": {
        "id": "yTAgJK0VLVaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roc curve for Train data"
      ],
      "metadata": {
        "id": "omSB7IpiLZKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.plot_roc_curve(rf_bayes, X_ros, y_ros) "
      ],
      "metadata": {
        "id": "1w3ClGgPLelA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.plot_precision_recall_curve(rf_bayes, X_ros, y_ros)"
      ],
      "metadata": {
        "id": "w2PqGep8Lm0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roc curve for Test data"
      ],
      "metadata": {
        "id": "tMLXknUdLp7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.plot_roc_curve(rf_bayes, Xtest, ytest)"
      ],
      "metadata": {
        "id": "agNVaYsmLtqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.plot_precision_recall_curve(rf_bayes, Xtest, ytest)"
      ],
      "metadata": {
        "id": "nUM9ehJPL1KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning on LgbmClassifier"
      ],
      "metadata": {
        "id": "9tZc1-HTL9sT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm = ltb.LGBMClassifier()\n",
        "#Cross validation and hyperparameter tuning\n",
        "lg_bayes = BayesSearchCV(estimator= lgbm,\n",
        "                         search_spaces = {\n",
        "                          'max_depth':Integer(4,100) ,\n",
        "                          'num_leaves': Integer(3,200),\n",
        "                          'n_estimators': Integer(3,200),\n",
        "                          'min_split_gain': Integer(1.0,10.0),\n",
        "                          'n_jobs': Integer(1,30),\n",
        "                        },\n",
        "                       cv = 5, verbose=2, scoring='accuracy', n_iter=10)\n",
        "\n",
        "lg_bayes.fit(X_ros,y_ros)"
      ],
      "metadata": {
        "id": "K9-k1yB6MWoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lg_bayes.best_params_"
      ],
      "metadata": {
        "id": "zQ2a6trwMZjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lg_bayes.best_estimator_"
      ],
      "metadata": {
        "id": "t5B96SR8McZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make prediction\n",
        "lgtrain_pred=lg_bayes.best_estimator_.predict(X_ros)\n",
        "lgtest_pred=lg_bayes.best_estimator_.predict(Xtest)"
      ],
      "metadata": {
        "id": "ktprJ2ASMfJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating accuracy on train and test\n",
        "train_accuracy = accuracy_score(y_ros, lgtrain_pred)\n",
        "test_accuracy = accuracy_score(ytest, lgtest_pred)\n",
        "\n",
        "print(\"The accuracy on train dataset is\", train_accuracy)\n",
        "print(\"The accuracy on test dataset is\", test_accuracy)"
      ],
      "metadata": {
        "id": "fv_3N9_uMkHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the confusion matrices for train and test\n",
        "train_cm = confusion_matrix(y_ros, lgtrain_pred)\n",
        "test_cm = confusion_matrix(ytest, lgtest_pred)"
      ],
      "metadata": {
        "id": "sXXVLE7QMtkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classification report for train and test\n",
        "print(classification_report(y_ros,lgtrain_pred))\n",
        "print(\"\\n\")\n",
        "print(classification_report(ytest,lgtest_pred))"
      ],
      "metadata": {
        "id": "IH-oyB_WMxfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roc curve for Train data"
      ],
      "metadata": {
        "id": "ddzGTvigM0qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.plot_roc_curve(lg_bayes, X_ros, y_ros) "
      ],
      "metadata": {
        "id": "d2aU0XPlM3OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.plot_precision_recall_curve(lg_bayes, X_ros, y_ros)"
      ],
      "metadata": {
        "id": "vt6BByg4M7Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roc Curve for Test data"
      ],
      "metadata": {
        "id": "muQBFIXqM74s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.plot_roc_curve(lg_bayes, Xtest, ytest)metrics.plot_precision_recall_curve(lg_bayes, Xtest, ytest)"
      ],
      "metadata": {
        "id": "uxSDumQQNAMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.plot_precision_recall_curve(lg_bayes, Xtest, ytest)Observation"
      ],
      "metadata": {
        "id": "oI1_dX6tNC8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Observation**"
      ],
      "metadata": {
        "id": "eLgy_zTqNGMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML model for the problem statement was created using python with the help of the dataset, and the ML model created with LGBM and Random Forest models performed better than other models.\n",
        "\n",
        "In comparison to both models, the LGBM model performed well on the most essential evaluation metric, 'Recall,' with values of 0.95 on train data and 0.92 on test data. As a result, we conclude LGBMClassifier is the best model for this dataset."
      ],
      "metadata": {
        "id": "UFEvssZmNKoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally, let us highlight the most important features that will be beneficial to the client.\n"
      ],
      "metadata": {
        "id": "WQOYhA-kNL4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances = lg_bayes.best_estimator_.feature_importances_\n",
        "importance_dict = {'Feature' : train_col_list,\n",
        "                   'Feature Importance' : importances}\n",
        "importance_df = pd.DataFrame(importance_dict)"
      ],
      "metadata": {
        "id": "hPmPKAUvNSWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df['Feature Importance'] = round(importance_df['Feature Importance'],2)"
      ],
      "metadata": {
        "id": "ynemNhMLNXo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Our top feature in descending order\n",
        "importance_df.sort_values(by=['Feature Importance'],ascending=False)"
      ],
      "metadata": {
        "id": "Jl1FAw4_NbXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most significant features are listed from top to bottom.\n",
        "\n"
      ],
      "metadata": {
        "id": "tdin8USCNgc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##**Conclusion:**"
      ],
      "metadata": {
        "id": "bfm779c2Nkwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our client is an insurance firm that has supplied Health Insurance to its customers. They now need assistance in developing a model to predict whether the policyholders (customers) from the previous year will be interested in the company's Vehicle Insurance.\n",
        "\n",
        "Building a model to predict if a client is interested in Vehicle Insurance is extremely beneficial to the company because they can then plan communication strategy to reach out to those customers and optimise its business model and revenue.\n",
        "\n",
        "Now, we have information about demographics (gender, age, region code type), vehicles (vehicle age, damage), policies (premium, sourcing channel), and so on to predict whether the customer would be interested in Vehicle insurance."
      ],
      "metadata": {
        "id": "sdubq5o_NqGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key points:\n",
        "\n",
        "Customers of age between 30 to 60 are more likely to buy insurance.\n",
        "\n",
        "Customers with Vehicle_Damage are likely to buy insurance.\n",
        "\n",
        "Customers with Driving License have higher chance of buying Insurance.\n",
        "\n",
        "The variable such as Age, Previously_insured,Annual_premium are more affecting the target variable.\n",
        "\n",
        "We can see that LGBM model preform better for this dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "4l1nttVcNuP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improvements:\n",
        "\n",
        "By using a marketing and advertising approach, we can reduce the gender gap.\n",
        "\n",
        "We can clearly see that we have a larger number of consumers without vehicle insurance, therefore we can easily target them directly with our campaign.\n",
        "\n",
        "Since there are less policy holders with vehicles older than two years, we must pay more attention to the other two categories (1-2 years and >1 year). Because most sales agencies that offer vehicle insurance for the first year are actually our target and we can give them the best incentives to reduce competition in the market.\n",
        "\n",
        "As we saw that we have nearly equal policy holders for both vehicle damage status, so we can target those policy holders whose vehicles are damaged in the past."
      ],
      "metadata": {
        "id": "JhcpvspjNvRs"
      }
    }
  ]
}